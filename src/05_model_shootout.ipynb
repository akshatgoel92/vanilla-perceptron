{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "%reset -f\n",
    "from helpers import load_all_data, vectorized_flatten, sigmoid, get_log_loss, get_accuracy, sigmoid_derivative, gradient_update, get_loss_plot, plot_loss\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "def prep_data(data_path):\n",
    "    '''\n",
    "    --------------------\n",
    "    Perceptron algorithm\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/0) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    \n",
    "    w: trained weights\n",
    "    y_hat: predictions\n",
    "    --------------------\n",
    "    '''\n",
    "    # Get datasets\n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = load_all_data(data_path)\n",
    "    \n",
    "    # Flatten datasets\n",
    "    X_train_flattened = vectorized_flatten(X_train)\n",
    "    X_dev_flattened = vectorized_flatten(X_dev)\n",
    "    X_test_flattened = vectorized_flatten(X_test)\n",
    "    \n",
    "    # Recode 0 to -1\n",
    "    y_train[np.where(y_train == 0)] = -1\n",
    "    y_test[np.where(y_train == 0)] = -1\n",
    "    y_dev[np.where(y_train == 0)] = -1\n",
    "    \n",
    "\n",
    "    # Add extra column to Y_train\n",
    "    y_train = y_train.reshape(1, -1)\n",
    "    y_dev = y_dev.reshape(1, -1)\n",
    "    y_test = y_test.reshape(1, -1)\n",
    "    \n",
    "    return(X_train_flattened, X_dev_flattened, X_test_flattened, y_train, y_dev, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X, Y, epochs):\n",
    "    '''\n",
    "    --------------------\n",
    "    Perceptron algorithm\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/-1) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    b: trained biases\n",
    "    y_preds: predictions \n",
    "    --------------------\n",
    "    '''\n",
    "    # Initialize weights and biases\n",
    "    w = np.zeros(X.shape[0])\n",
    "    b = 0\n",
    "    \n",
    "    # Run for a fixed number of epochs\n",
    "    for epoch in range(1, epochs + 1): \n",
    "        \n",
    "        # Do this for each example in the dataset\n",
    "        for i in range(X.shape[1]):\n",
    "            \n",
    "            # Store the sample data\n",
    "            x_i = X[:, i]\n",
    "            y_i = Y[0][i]\n",
    "            \n",
    "            # Compute the prediction with the current weights\n",
    "            if (np.dot(w, x_i) + b > 0): y_hat = 1\n",
    "            else: y_hat = -1\n",
    "            \n",
    "            # Check if the prediction is correct against the labels\n",
    "            # If it is correct we don't need to make any updates: we just move to the next iteration\n",
    "            # If it is not correct then we do the following: \n",
    "            # 1) Update the error flag to show there is still a misclassification \n",
    "            # 2) Update the weights and biases in the direction of the label\n",
    "            if y_hat != y_i:\n",
    "                w = w + y_i*x_i\n",
    "                b = b + y_i\n",
    "            \n",
    "            # Monitor accuracy every 6000 samples\n",
    "            if i % 6000 == 0:\n",
    "                \n",
    "                # Get predictions\n",
    "                y_preds = np.array([int(np.dot(w, X[:, i]) + b  > 0) for i in range(X.shape[1])])\n",
    "        \n",
    "                # Training accuracy                       \n",
    "                train_accuracy = get_accuracy(Y, y_preds)\n",
    "        \n",
    "                # Get training accuracy\n",
    "                print(\"Epoch {}/{}: Training_accuracy = {}\".format(epoch, epochs, train_accuracy))\n",
    "    \n",
    "    # Return statement\n",
    "    return(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perceptron_performance(w, b, X, Y): \n",
    "    '''\n",
    "    --------------------\n",
    "    Run perceptron algorithm to get a base-line\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/0) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    y_preds: predictions\n",
    "    --------------------\n",
    "    '''\n",
    "    # Get predictions\n",
    "    y_preds = np.array([int(np.dot(w, X[:, i]) + b  > 0) for i in range(X.shape[1])])\n",
    "        \n",
    "    # Training accuracy                       \n",
    "    train_accuracy = get_accuracy(Y, y_preds)\n",
    "    \n",
    "    # Return statement\n",
    "    return(y_preds, train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perceptron_baseline(data_path, epochs):\n",
    "    '''\n",
    "    --------------------\n",
    "    Run perceptron algorithm to get a base-line\n",
    "    --------------------\n",
    "    Parameters: \n",
    "    X: Numpy array of training features (shape = 784 X n)\n",
    "    y: Binary (1/0) training label (shape = n X 1)\n",
    "    --------------------\n",
    "    Output: \n",
    "    w: trained weights\n",
    "    y_preds: predictions\n",
    "    --------------------\n",
    "    '''\n",
    "    # Set the random seed for np.random number generator\n",
    "    # This will make sure results are reproducible\n",
    "    np.random.seed(132089)\n",
    "    \n",
    "    # Prepare data for the perceptron\n",
    "    X_train_flattened, X_dev_flattened, X_test_flattened, y_train, y_dev, y_test = prep_data(data_path)\n",
    "    \n",
    "    # Call the perceptron training with the given epochs\n",
    "    w, b = train_perceptron(X_train_flattened, y_train, epochs)\n",
    "    \n",
    "    # Get train set performance\n",
    "    train_preds, train_accuracy = get_perceptron_performance(w, b, X_train_flattened, y_train)\n",
    "    \n",
    "    # Get dev set performance\n",
    "    dev_preds, dev_accuracy = get_perceptron_performance(w, b, X_dev_flattened, y_dev)\n",
    "    \n",
    "    # Return statement\n",
    "    return(w, b, train_preds, dev_preds, train_accuracy, dev_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Training_accuracy = 0.0\n",
      "Epoch 1/100: Training_accuracy = 0.4275833333333333\n",
      "Epoch 2/100: Training_accuracy = 0.49175\n",
      "Epoch 2/100: Training_accuracy = 0.44175\n",
      "Epoch 3/100: Training_accuracy = 0.49433333333333335\n",
      "Epoch 3/100: Training_accuracy = 0.45975\n",
      "Epoch 4/100: Training_accuracy = 0.488\n",
      "Epoch 4/100: Training_accuracy = 0.379\n",
      "Epoch 5/100: Training_accuracy = 0.4900833333333333\n",
      "Epoch 5/100: Training_accuracy = 0.45416666666666666\n",
      "Epoch 6/100: Training_accuracy = 0.4865\n",
      "Epoch 6/100: Training_accuracy = 0.46908333333333335\n",
      "Epoch 7/100: Training_accuracy = 0.4890833333333333\n",
      "Epoch 7/100: Training_accuracy = 0.46408333333333335\n",
      "Epoch 8/100: Training_accuracy = 0.493\n",
      "Epoch 8/100: Training_accuracy = 0.46558333333333335\n",
      "Epoch 9/100: Training_accuracy = 0.4925\n",
      "Epoch 9/100: Training_accuracy = 0.46491666666666664\n",
      "Epoch 10/100: Training_accuracy = 0.49333333333333335\n",
      "Epoch 10/100: Training_accuracy = 0.45116666666666666\n",
      "Epoch 11/100: Training_accuracy = 0.4905\n",
      "Epoch 11/100: Training_accuracy = 0.4544166666666667\n",
      "Epoch 12/100: Training_accuracy = 0.4866666666666667\n",
      "Epoch 12/100: Training_accuracy = 0.48241666666666666\n",
      "Epoch 13/100: Training_accuracy = 0.48491666666666666\n",
      "Epoch 13/100: Training_accuracy = 0.4569166666666667\n",
      "Epoch 14/100: Training_accuracy = 0.49525\n",
      "Epoch 14/100: Training_accuracy = 0.45325\n",
      "Epoch 15/100: Training_accuracy = 0.49566666666666664\n",
      "Epoch 15/100: Training_accuracy = 0.46991666666666665\n",
      "Epoch 16/100: Training_accuracy = 0.49075\n",
      "Epoch 16/100: Training_accuracy = 0.4605\n",
      "Epoch 17/100: Training_accuracy = 0.49191666666666667\n",
      "Epoch 17/100: Training_accuracy = 0.31466666666666665\n",
      "Epoch 18/100: Training_accuracy = 0.49283333333333335\n",
      "Epoch 18/100: Training_accuracy = 0.4755\n",
      "Epoch 19/100: Training_accuracy = 0.48933333333333334\n",
      "Epoch 19/100: Training_accuracy = 0.446\n",
      "Epoch 20/100: Training_accuracy = 0.49025\n",
      "Epoch 20/100: Training_accuracy = 0.3338333333333333\n",
      "Epoch 21/100: Training_accuracy = 0.49025\n",
      "Epoch 21/100: Training_accuracy = 0.372\n",
      "Epoch 22/100: Training_accuracy = 0.4945\n",
      "Epoch 22/100: Training_accuracy = 0.4800833333333333\n",
      "Epoch 23/100: Training_accuracy = 0.48783333333333334\n",
      "Epoch 23/100: Training_accuracy = 0.4791666666666667\n",
      "Epoch 24/100: Training_accuracy = 0.49616666666666664\n",
      "Epoch 24/100: Training_accuracy = 0.4638333333333333\n",
      "Epoch 25/100: Training_accuracy = 0.487\n",
      "Epoch 25/100: Training_accuracy = 0.4718333333333333\n",
      "Epoch 26/100: Training_accuracy = 0.49583333333333335\n",
      "Epoch 26/100: Training_accuracy = 0.486\n",
      "Epoch 27/100: Training_accuracy = 0.4925\n",
      "Epoch 27/100: Training_accuracy = 0.4523333333333333\n",
      "Epoch 28/100: Training_accuracy = 0.4920833333333333\n",
      "Epoch 28/100: Training_accuracy = 0.33891666666666664\n",
      "Epoch 29/100: Training_accuracy = 0.49341666666666667\n",
      "Epoch 29/100: Training_accuracy = 0.47058333333333335\n",
      "Epoch 30/100: Training_accuracy = 0.4886666666666667\n",
      "Epoch 30/100: Training_accuracy = 0.46\n",
      "Epoch 31/100: Training_accuracy = 0.49233333333333335\n",
      "Epoch 31/100: Training_accuracy = 0.46858333333333335\n",
      "Epoch 32/100: Training_accuracy = 0.49333333333333335\n",
      "Epoch 32/100: Training_accuracy = 0.46725\n",
      "Epoch 33/100: Training_accuracy = 0.48691666666666666\n",
      "Epoch 33/100: Training_accuracy = 0.457\n",
      "Epoch 34/100: Training_accuracy = 0.49466666666666664\n",
      "Epoch 34/100: Training_accuracy = 0.3581666666666667\n",
      "Epoch 35/100: Training_accuracy = 0.49441666666666667\n",
      "Epoch 35/100: Training_accuracy = 0.4545\n",
      "Epoch 36/100: Training_accuracy = 0.4870833333333333\n",
      "Epoch 36/100: Training_accuracy = 0.46075\n",
      "Epoch 37/100: Training_accuracy = 0.49241666666666667\n",
      "Epoch 37/100: Training_accuracy = 0.47841666666666666\n",
      "Epoch 38/100: Training_accuracy = 0.48383333333333334\n",
      "Epoch 38/100: Training_accuracy = 0.4715\n",
      "Epoch 39/100: Training_accuracy = 0.4905833333333333\n",
      "Epoch 39/100: Training_accuracy = 0.4726666666666667\n",
      "Epoch 40/100: Training_accuracy = 0.4915\n",
      "Epoch 40/100: Training_accuracy = 0.38158333333333333\n",
      "Epoch 41/100: Training_accuracy = 0.49191666666666667\n",
      "Epoch 41/100: Training_accuracy = 0.4821666666666667\n",
      "Epoch 42/100: Training_accuracy = 0.4905833333333333\n",
      "Epoch 42/100: Training_accuracy = 0.41691666666666666\n",
      "Epoch 43/100: Training_accuracy = 0.49175\n",
      "Epoch 43/100: Training_accuracy = 0.41425\n",
      "Epoch 44/100: Training_accuracy = 0.48733333333333334\n",
      "Epoch 44/100: Training_accuracy = 0.4830833333333333\n",
      "Epoch 45/100: Training_accuracy = 0.49016666666666664\n",
      "Epoch 45/100: Training_accuracy = 0.4880833333333333\n",
      "Epoch 46/100: Training_accuracy = 0.49216666666666664\n",
      "Epoch 46/100: Training_accuracy = 0.4835\n",
      "Epoch 47/100: Training_accuracy = 0.49316666666666664\n",
      "Epoch 47/100: Training_accuracy = 0.37066666666666664\n",
      "Epoch 48/100: Training_accuracy = 0.495\n",
      "Epoch 48/100: Training_accuracy = 0.4810833333333333\n",
      "Epoch 49/100: Training_accuracy = 0.492\n",
      "Epoch 49/100: Training_accuracy = 0.4870833333333333\n",
      "Epoch 50/100: Training_accuracy = 0.49525\n",
      "Epoch 50/100: Training_accuracy = 0.45525\n",
      "Epoch 51/100: Training_accuracy = 0.49516666666666664\n",
      "Epoch 51/100: Training_accuracy = 0.36325\n",
      "Epoch 52/100: Training_accuracy = 0.4935833333333333\n",
      "Epoch 52/100: Training_accuracy = 0.4835833333333333\n",
      "Epoch 53/100: Training_accuracy = 0.4886666666666667\n",
      "Epoch 53/100: Training_accuracy = 0.46775\n",
      "Epoch 54/100: Training_accuracy = 0.49091666666666667\n",
      "Epoch 54/100: Training_accuracy = 0.47683333333333333\n",
      "Epoch 55/100: Training_accuracy = 0.49291666666666667\n",
      "Epoch 55/100: Training_accuracy = 0.4688333333333333\n",
      "Epoch 56/100: Training_accuracy = 0.4930833333333333\n",
      "Epoch 56/100: Training_accuracy = 0.46741666666666665\n",
      "Epoch 57/100: Training_accuracy = 0.49091666666666667\n",
      "Epoch 57/100: Training_accuracy = 0.48\n",
      "Epoch 58/100: Training_accuracy = 0.49333333333333335\n",
      "Epoch 58/100: Training_accuracy = 0.47833333333333333\n",
      "Epoch 59/100: Training_accuracy = 0.48475\n",
      "Epoch 59/100: Training_accuracy = 0.4191666666666667\n",
      "Epoch 60/100: Training_accuracy = 0.49225\n",
      "Epoch 60/100: Training_accuracy = 0.4855833333333333\n",
      "Epoch 61/100: Training_accuracy = 0.49341666666666667\n",
      "Epoch 61/100: Training_accuracy = 0.4886666666666667\n",
      "Epoch 62/100: Training_accuracy = 0.495\n",
      "Epoch 62/100: Training_accuracy = 0.4494166666666667\n",
      "Epoch 63/100: Training_accuracy = 0.49033333333333334\n",
      "Epoch 63/100: Training_accuracy = 0.4845833333333333\n",
      "Epoch 64/100: Training_accuracy = 0.49125\n",
      "Epoch 64/100: Training_accuracy = 0.47175\n",
      "Epoch 65/100: Training_accuracy = 0.49533333333333335\n",
      "Epoch 65/100: Training_accuracy = 0.47541666666666665\n",
      "Epoch 66/100: Training_accuracy = 0.4935\n",
      "Epoch 66/100: Training_accuracy = 0.4870833333333333\n",
      "Epoch 67/100: Training_accuracy = 0.4935833333333333\n",
      "Epoch 67/100: Training_accuracy = 0.47991666666666666\n",
      "Epoch 68/100: Training_accuracy = 0.4935833333333333\n",
      "Epoch 68/100: Training_accuracy = 0.4870833333333333\n",
      "Epoch 69/100: Training_accuracy = 0.49291666666666667\n",
      "Epoch 69/100: Training_accuracy = 0.4825\n",
      "Epoch 70/100: Training_accuracy = 0.4930833333333333\n",
      "Epoch 70/100: Training_accuracy = 0.4795\n",
      "Epoch 71/100: Training_accuracy = 0.4925\n",
      "Epoch 71/100: Training_accuracy = 0.4895\n",
      "Epoch 72/100: Training_accuracy = 0.49066666666666664\n",
      "Epoch 72/100: Training_accuracy = 0.4665\n",
      "Epoch 73/100: Training_accuracy = 0.4955833333333333\n",
      "Epoch 73/100: Training_accuracy = 0.4816666666666667\n",
      "Epoch 74/100: Training_accuracy = 0.48975\n",
      "Epoch 74/100: Training_accuracy = 0.48683333333333334\n",
      "Epoch 75/100: Training_accuracy = 0.49383333333333335\n",
      "Epoch 75/100: Training_accuracy = 0.48425\n",
      "Epoch 76/100: Training_accuracy = 0.49483333333333335\n",
      "Epoch 76/100: Training_accuracy = 0.4856666666666667\n",
      "Epoch 77/100: Training_accuracy = 0.49175\n",
      "Epoch 77/100: Training_accuracy = 0.47891666666666666\n",
      "Epoch 78/100: Training_accuracy = 0.48941666666666667\n",
      "Epoch 78/100: Training_accuracy = 0.4588333333333333\n",
      "Epoch 79/100: Training_accuracy = 0.4895\n",
      "Epoch 79/100: Training_accuracy = 0.48425\n",
      "Epoch 80/100: Training_accuracy = 0.49533333333333335\n",
      "Epoch 80/100: Training_accuracy = 0.49133333333333334\n",
      "Epoch 81/100: Training_accuracy = 0.49125\n",
      "Epoch 81/100: Training_accuracy = 0.4695\n",
      "Epoch 82/100: Training_accuracy = 0.49575\n",
      "Epoch 82/100: Training_accuracy = 0.46508333333333335\n",
      "Epoch 83/100: Training_accuracy = 0.4935833333333333\n",
      "Epoch 83/100: Training_accuracy = 0.4745\n",
      "Epoch 84/100: Training_accuracy = 0.49391666666666667\n",
      "Epoch 84/100: Training_accuracy = 0.44433333333333336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: Training_accuracy = 0.4940833333333333\n",
      "Epoch 85/100: Training_accuracy = 0.47758333333333336\n",
      "Epoch 86/100: Training_accuracy = 0.4945\n",
      "Epoch 86/100: Training_accuracy = 0.47891666666666666\n",
      "Epoch 87/100: Training_accuracy = 0.49391666666666667\n",
      "Epoch 87/100: Training_accuracy = 0.4851666666666667\n",
      "Epoch 88/100: Training_accuracy = 0.49533333333333335\n",
      "Epoch 88/100: Training_accuracy = 0.48391666666666666\n",
      "Epoch 89/100: Training_accuracy = 0.488\n",
      "Epoch 89/100: Training_accuracy = 0.474\n",
      "Epoch 90/100: Training_accuracy = 0.48891666666666667\n",
      "Epoch 90/100: Training_accuracy = 0.47858333333333336\n",
      "Epoch 91/100: Training_accuracy = 0.49616666666666664\n",
      "Epoch 91/100: Training_accuracy = 0.4845\n",
      "Epoch 92/100: Training_accuracy = 0.49566666666666664\n",
      "Epoch 92/100: Training_accuracy = 0.48341666666666666\n",
      "Epoch 93/100: Training_accuracy = 0.49216666666666664\n",
      "Epoch 93/100: Training_accuracy = 0.4075\n",
      "Epoch 94/100: Training_accuracy = 0.4960833333333333\n",
      "Epoch 94/100: Training_accuracy = 0.43233333333333335\n",
      "Epoch 95/100: Training_accuracy = 0.49316666666666664\n",
      "Epoch 95/100: Training_accuracy = 0.48783333333333334\n",
      "Epoch 96/100: Training_accuracy = 0.49383333333333335\n",
      "Epoch 96/100: Training_accuracy = 0.46758333333333335\n",
      "Epoch 97/100: Training_accuracy = 0.491\n",
      "Epoch 97/100: Training_accuracy = 0.4563333333333333\n",
      "Epoch 98/100: Training_accuracy = 0.49141666666666667\n",
      "Epoch 98/100: Training_accuracy = 0.48525\n",
      "Epoch 99/100: Training_accuracy = 0.49475\n",
      "Epoch 99/100: Training_accuracy = 0.47125\n",
      "Epoch 100/100: Training_accuracy = 0.4940833333333333\n",
      "Epoch 100/100: Training_accuracy = 0.48275\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "data_path = '../setup/data'\n",
    "epochs = 100\n",
    "\n",
    "# Call training function\n",
    "w, b, train_preds, dev_preds, train_accuracy, dev_accuracy = get_perceptron_baseline(data_path, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4945, 0.95)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "train_accuracy, dev_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
